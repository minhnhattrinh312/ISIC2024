{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e07881c",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-08-04T14:00:02.074688Z",
     "iopub.status.busy": "2024-08-04T14:00:02.074332Z",
     "iopub.status.idle": "2024-08-04T14:01:19.707114Z",
     "shell.execute_reply": "2024-08-04T14:01:19.706253Z"
    },
    "papermill": {
     "duration": 77.640153,
     "end_time": "2024-08-04T14:01:19.709631",
     "exception": false,
     "start_time": "2024-08-04T14:00:02.069478",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/isic2024-git/library/lightning-2.3.3-py3-none-any.whl\r\n",
      "Requirement already satisfied: PyYAML<8.0,>=5.4 in /opt/conda/lib/python3.10/site-packages (from lightning==2.3.3) (6.0.1)\r\n",
      "Requirement already satisfied: fsspec<2026.0,>=2022.5.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning==2.3.3) (2024.5.0)\r\n",
      "Requirement already satisfied: lightning-utilities<2.0,>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from lightning==2.3.3) (0.11.3.post0)\r\n",
      "Requirement already satisfied: numpy<3.0,>=1.17.2 in /opt/conda/lib/python3.10/site-packages (from lightning==2.3.3) (1.26.4)\r\n",
      "Requirement already satisfied: packaging<25.0,>=20.0 in /opt/conda/lib/python3.10/site-packages (from lightning==2.3.3) (21.3)\r\n",
      "Requirement already satisfied: torch<4.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from lightning==2.3.3) (2.1.2)\r\n",
      "Requirement already satisfied: torchmetrics<3.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from lightning==2.3.3) (1.4.0.post0)\r\n",
      "Requirement already satisfied: tqdm<6.0,>=4.57.0 in /opt/conda/lib/python3.10/site-packages (from lightning==2.3.3) (4.66.4)\r\n",
      "Requirement already satisfied: typing-extensions<6.0,>=4.4.0 in /opt/conda/lib/python3.10/site-packages (from lightning==2.3.3) (4.9.0)\r\n",
      "Requirement already satisfied: pytorch-lightning in /opt/conda/lib/python3.10/site-packages (from lightning==2.3.3) (2.3.3)\r\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning==2.3.3) (3.9.1)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from lightning-utilities<2.0,>=0.10.0->lightning==2.3.3) (69.0.3)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging<25.0,>=20.0->lightning==2.3.3) (3.1.1)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch<4.0,>=2.0.0->lightning==2.3.3) (3.13.1)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch<4.0,>=2.0.0->lightning==2.3.3) (1.13.0)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch<4.0,>=2.0.0->lightning==2.3.3) (3.2.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch<4.0,>=2.0.0->lightning==2.3.3) (3.1.2)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning==2.3.3) (23.2.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning==2.3.3) (6.0.4)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning==2.3.3) (1.9.3)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning==2.3.3) (1.4.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning==2.3.3) (1.3.1)\r\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning==2.3.3) (4.0.3)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch<4.0,>=2.0.0->lightning==2.3.3) (2.1.3)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch<4.0,>=2.0.0->lightning==2.3.3) (1.3.0)\r\n",
      "Requirement already satisfied: idna>=2.0 in /opt/conda/lib/python3.10/site-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning==2.3.3) (3.6)\r\n",
      "Installing collected packages: lightning\r\n",
      "Successfully installed lightning-2.3.3\r\n",
      "Processing /kaggle/input/isic2024-git/library/yacs-0.1.8-py3-none-any.whl\r\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from yacs==0.1.8) (6.0.1)\r\n",
      "Installing collected packages: yacs\r\n",
      "Successfully installed yacs-0.1.8\r\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "from IPython.display import clear_output\n",
    "!pip install \"/kaggle/input/isic2024-git/library/lightning-2.3.3-py3-none-any.whl\"\n",
    "!pip install \"/kaggle/input/isic2024-git/library/yacs-0.1.8-py3-none-any.whl\"\n",
    "# clear_output()\n",
    "import numpy as np  # linear algebra\n",
    "import pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import os\n",
    "import sys\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset\n",
    "import torch._dynamo\n",
    "\n",
    "torch._dynamo.config.suppress_errors = True\n",
    "\n",
    "import timm\n",
    "sys.path.append(\"/kaggle/input/isic2024-git\")\n",
    "import h5py\n",
    "import io\n",
    "from tqdm import tqdm\n",
    "from classification import *\n",
    "from lightning.pytorch import Trainer\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "torch.set_float32_matmul_precision(\"high\")\n",
    "def read_images_from_hdf5(file_path):\n",
    "    images = {}\n",
    "    try:\n",
    "        with h5py.File(file_path, \"r\") as file:\n",
    "            for key in tqdm(file.keys(), desc=\"Reading Files\"):\n",
    "                try:\n",
    "                    image_data = file[key][()]\n",
    "                    image = Image.open(io.BytesIO(image_data))\n",
    "                    images[key] = image\n",
    "                except Exception as e:\n",
    "                    print(f\"Error! from {key}: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error occured while reading files : {e}\")\n",
    "\n",
    "    return images\n",
    "\n",
    "\n",
    "def predict_images(model, dataloader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for images in tqdm(dataloader, desc=\"Prediction Loop\"):\n",
    "            images = images.to(device)\n",
    "            preds = model(images)\n",
    "            all_preds.extend(preds.cpu().numpy()[:, 1])\n",
    "\n",
    "    return np.stack(all_preds)\n",
    "\n",
    "\n",
    "class ISIC_test_image(Dataset):\n",
    "    def __init__(self, pil_images, metadata):\n",
    "        self.pil_images = pil_images\n",
    "        self.isic_ids = metadata[\"isic_id\"].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.isic_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.pil_images[self.isic_ids[idx]].resize((224, 224))\n",
    "        image = transforms.ToTensor()(image)\n",
    "\n",
    "        return image\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "836386cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T14:01:19.719512Z",
     "iopub.status.busy": "2024-08-04T14:01:19.718984Z",
     "iopub.status.idle": "2024-08-04T14:01:19.723454Z",
     "shell.execute_reply": "2024-08-04T14:01:19.722609Z"
    },
    "papermill": {
     "duration": 0.011357,
     "end_time": "2024-08-04T14:01:19.725334",
     "exception": false,
     "start_time": "2024-08-04T14:01:19.713977",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TEST_METADATA = \"/kaggle/input/isic-2024-challenge/test-metadata.csv\"\n",
    "TEST_HDF5 = \"/kaggle/input/isic-2024-challenge/test-image.hdf5\"\n",
    "TEST_SUBMISSION = \"/kaggle/input/isic-2024-challenge/sample_submission.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71a54d16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T14:01:19.733689Z",
     "iopub.status.busy": "2024-08-04T14:01:19.733421Z",
     "iopub.status.idle": "2024-08-04T14:01:19.798271Z",
     "shell.execute_reply": "2024-08-04T14:01:19.797368Z"
    },
    "papermill": {
     "duration": 0.071368,
     "end_time": "2024-08-04T14:01:19.800323",
     "exception": false,
     "start_time": "2024-08-04T14:01:19.728955",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading Files: 100%|██████████| 3/3 [00:00<00:00, 417.88it/s]\n"
     ]
    }
   ],
   "source": [
    "test_images = read_images_from_hdf5(TEST_HDF5)\n",
    "test_metadata = pd.read_csv(TEST_METADATA)\n",
    "\n",
    "test_loader = ISIC_test_image(test_images, test_metadata)\n",
    "\n",
    "test_dataset = DataLoader(\n",
    "    test_loader,\n",
    "    batch_size=16,\n",
    "    num_workers=4,\n",
    "    prefetch_factor=8,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c32893c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T14:01:19.809170Z",
     "iopub.status.busy": "2024-08-04T14:01:19.808848Z",
     "iopub.status.idle": "2024-08-04T14:02:16.513850Z",
     "shell.execute_reply": "2024-08-04T14:02:16.512525Z"
    },
    "papermill": {
     "duration": 56.711895,
     "end_time": "2024-08-04T14:02:16.516088",
     "exception": false,
     "start_time": "2024-08-04T14:01:19.804193",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint: /kaggle/input/convnext/pytorch/default/1/ckpt_auc_0.1943-v1.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prediction Loop:   0%|          | 0/1 [00:00<?, ?it/s][2024-08-04 14:01:46,722] torch._dynamo.convert_frame: [WARNING] WON'T CONVERT forward /kaggle/input/isic2024-git/classification/convNext_model.py line 110 \n",
      "[2024-08-04 14:01:46,722] torch._dynamo.convert_frame: [WARNING] due to: \n",
      "[2024-08-04 14:01:46,722] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):\n",
      "[2024-08-04 14:01:46,722] torch._dynamo.convert_frame: [WARNING]   File \"/opt/conda/lib/python3.10/site-packages/torch/_inductor/scheduler.py\", line 1630, in create_backend\n",
      "[2024-08-04 14:01:46,722] torch._dynamo.convert_frame: [WARNING]     raise RuntimeError(\n",
      "[2024-08-04 14:01:46,722] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "[2024-08-04 14:01:46,722] torch._dynamo.convert_frame: [WARNING] RuntimeError: Found Tesla P100-PCIE-16GB which is too old to be supported by the triton GPU compiler, which is used as the backend. Triton only supports devices of CUDA Capability >= 7.0, but your device is of CUDA capability 6.0\n",
      "[2024-08-04 14:01:46,722] torch._dynamo.convert_frame: [WARNING] \n",
      "[2024-08-04 14:01:46,722] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "[2024-08-04 14:01:46,722] torch._dynamo.convert_frame: [WARNING] \n",
      "[2024-08-04 14:01:46,722] torch._dynamo.convert_frame: [WARNING] \n",
      "[2024-08-04 14:02:03,031] torch._dynamo.convert_frame: [WARNING] WON'T CONVERT forward_features /kaggle/input/isic2024-git/classification/convNext_model.py line 104 \n",
      "[2024-08-04 14:02:03,031] torch._dynamo.convert_frame: [WARNING] due to: \n",
      "[2024-08-04 14:02:03,031] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):\n",
      "[2024-08-04 14:02:03,031] torch._dynamo.convert_frame: [WARNING]   File \"/opt/conda/lib/python3.10/site-packages/torch/_inductor/scheduler.py\", line 1630, in create_backend\n",
      "[2024-08-04 14:02:03,031] torch._dynamo.convert_frame: [WARNING]     raise RuntimeError(\n",
      "[2024-08-04 14:02:03,031] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "[2024-08-04 14:02:03,031] torch._dynamo.convert_frame: [WARNING] RuntimeError: Found Tesla P100-PCIE-16GB which is too old to be supported by the triton GPU compiler, which is used as the backend. Triton only supports devices of CUDA Capability >= 7.0, but your device is of CUDA capability 6.0\n",
      "[2024-08-04 14:02:03,031] torch._dynamo.convert_frame: [WARNING] \n",
      "[2024-08-04 14:02:03,031] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "[2024-08-04 14:02:03,031] torch._dynamo.convert_frame: [WARNING] \n",
      "[2024-08-04 14:02:03,031] torch._dynamo.convert_frame: [WARNING] \n",
      "[2024-08-04 14:02:03,253] torch._dynamo.convert_frame: [WARNING] WON'T CONVERT forward /opt/conda/lib/python3.10/site-packages/torch/nn/modules/container.py line 213 \n",
      "[2024-08-04 14:02:03,253] torch._dynamo.convert_frame: [WARNING] due to: \n",
      "[2024-08-04 14:02:03,253] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):\n",
      "[2024-08-04 14:02:03,253] torch._dynamo.convert_frame: [WARNING]   File \"/opt/conda/lib/python3.10/site-packages/torch/_inductor/scheduler.py\", line 1630, in create_backend\n",
      "[2024-08-04 14:02:03,253] torch._dynamo.convert_frame: [WARNING]     raise RuntimeError(\n",
      "[2024-08-04 14:02:03,253] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "[2024-08-04 14:02:03,253] torch._dynamo.convert_frame: [WARNING] RuntimeError: Found Tesla P100-PCIE-16GB which is too old to be supported by the triton GPU compiler, which is used as the backend. Triton only supports devices of CUDA Capability >= 7.0, but your device is of CUDA capability 6.0\n",
      "[2024-08-04 14:02:03,253] torch._dynamo.convert_frame: [WARNING] \n",
      "[2024-08-04 14:02:03,253] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "[2024-08-04 14:02:03,253] torch._dynamo.convert_frame: [WARNING] \n",
      "[2024-08-04 14:02:03,253] torch._dynamo.convert_frame: [WARNING] \n",
      "[2024-08-04 14:02:03,771] torch._dynamo.convert_frame: [WARNING] WON'T CONVERT forward /kaggle/input/isic2024-git/classification/convNext_model.py line 133 \n",
      "[2024-08-04 14:02:03,771] torch._dynamo.convert_frame: [WARNING] due to: \n",
      "[2024-08-04 14:02:03,771] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):\n",
      "[2024-08-04 14:02:03,771] torch._dynamo.convert_frame: [WARNING]   File \"/opt/conda/lib/python3.10/site-packages/torch/_inductor/scheduler.py\", line 1630, in create_backend\n",
      "[2024-08-04 14:02:03,771] torch._dynamo.convert_frame: [WARNING]     raise RuntimeError(\n",
      "[2024-08-04 14:02:03,771] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "[2024-08-04 14:02:03,771] torch._dynamo.convert_frame: [WARNING] RuntimeError: Found Tesla P100-PCIE-16GB which is too old to be supported by the triton GPU compiler, which is used as the backend. Triton only supports devices of CUDA Capability >= 7.0, but your device is of CUDA capability 6.0\n",
      "[2024-08-04 14:02:03,771] torch._dynamo.convert_frame: [WARNING] \n",
      "[2024-08-04 14:02:03,771] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "[2024-08-04 14:02:03,771] torch._dynamo.convert_frame: [WARNING] \n",
      "[2024-08-04 14:02:03,771] torch._dynamo.convert_frame: [WARNING] \n",
      "[2024-08-04 14:02:04,209] torch._dynamo.convert_frame: [WARNING] WON'T CONVERT forward /kaggle/input/isic2024-git/classification/convNext_model.py line 33 \n",
      "[2024-08-04 14:02:04,209] torch._dynamo.convert_frame: [WARNING] due to: \n",
      "[2024-08-04 14:02:04,209] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):\n",
      "[2024-08-04 14:02:04,209] torch._dynamo.convert_frame: [WARNING]   File \"/opt/conda/lib/python3.10/site-packages/torch/_inductor/scheduler.py\", line 1630, in create_backend\n",
      "[2024-08-04 14:02:04,209] torch._dynamo.convert_frame: [WARNING]     raise RuntimeError(\n",
      "[2024-08-04 14:02:04,209] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "[2024-08-04 14:02:04,209] torch._dynamo.convert_frame: [WARNING] RuntimeError: Found Tesla P100-PCIE-16GB which is too old to be supported by the triton GPU compiler, which is used as the backend. Triton only supports devices of CUDA Capability >= 7.0, but your device is of CUDA capability 6.0\n",
      "[2024-08-04 14:02:04,209] torch._dynamo.convert_frame: [WARNING] \n",
      "[2024-08-04 14:02:04,209] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "[2024-08-04 14:02:04,209] torch._dynamo.convert_frame: [WARNING] \n",
      "[2024-08-04 14:02:04,209] torch._dynamo.convert_frame: [WARNING] \n",
      "Prediction Loop: 100%|██████████| 1/1 [00:37<00:00, 37.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint: /kaggle/input/convnext/pytorch/default/1/ckpt_auc_0.1943-v4.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prediction Loop: 100%|██████████| 1/1 [00:00<00:00,  6.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint: /kaggle/input/convnext/pytorch/default/1/ckpt_auc_0.1937.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prediction Loop: 100%|██████████| 1/1 [00:00<00:00,  6.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint: /kaggle/input/convnext/pytorch/default/1/ckpt_auc_0.1972-v3.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prediction Loop: 100%|██████████| 1/1 [00:00<00:00,  6.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint: /kaggle/input/convnext/pytorch/default/1/ckpt_recall_0.9606.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prediction Loop: 100%|██████████| 1/1 [00:00<00:00,  7.32it/s]\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = convnext_small(\n",
    "    pretrained=False,\n",
    "    in_22k=cfg.TRAIN.CONVEXT.IN22K,\n",
    "    in_chans=cfg.DATA.IN_CHANNEL,\n",
    "    num_classes=cfg.DATA.NUM_CLASS,\n",
    "    drop_path_rate=cfg.TRAIN.CONVEXT.DROPOUT,\n",
    ")\n",
    "# model = torch.compile(model)\n",
    "classifier = Classifier(\n",
    "    model,\n",
    "    cfg.DATA.CLASS_WEIGHT,\n",
    "    cfg.DATA.NUM_CLASS,\n",
    "    cfg.OPT.LEARNING_RATE,\n",
    "    cfg.OPT.FACTOR_LR,\n",
    "    cfg.OPT.PATIENCE_LR,\n",
    ")\n",
    "classifier = classifier.to(device)\n",
    "sum_predictions = 0\n",
    "\n",
    "for fold in range(1, 6):\n",
    "    checkpoint_dict = {\n",
    "        \"fold1\": \"/kaggle/input/convnext/pytorch/default/1/ckpt_auc_0.1943-v1.ckpt\",\n",
    "        \"fold2\": \"/kaggle/input/convnext/pytorch/default/1/ckpt_auc_0.1943-v4.ckpt\",\n",
    "        \"fold3\": \"/kaggle/input/convnext/pytorch/default/1/ckpt_auc_0.1937.ckpt\",\n",
    "        \"fold4\": \"/kaggle/input/convnext/pytorch/default/1/ckpt_auc_0.1972-v3.ckpt\",\n",
    "        \"fold5\": \"/kaggle/input/convnext/pytorch/default/1/ckpt_recall_0.9606.ckpt\",\n",
    "    }\n",
    "\n",
    "    # Select the second checkpoint in the list (index 0)\n",
    "    checkpoint = checkpoint_dict[f\"fold{fold}\"]\n",
    "    print(f\"load checkpoint: {checkpoint}\")\n",
    "    # Load the model weights from the selected checkpoint\n",
    "    classifier = Classifier.load_from_checkpoint(\n",
    "        checkpoint_path=checkpoint,\n",
    "        model=model,\n",
    "        class_weight=cfg.DATA.CLASS_WEIGHT,\n",
    "        num_classes=cfg.DATA.NUM_CLASS,\n",
    "        learning_rate=cfg.OPT.LEARNING_RATE,\n",
    "        factor_lr=cfg.OPT.FACTOR_LR,\n",
    "        patience_lr=cfg.OPT.PATIENCE_LR,\n",
    "    )\n",
    "    test_predictions = predict_images(classifier, test_dataset, device)\n",
    "    sum_predictions += test_predictions\n",
    "\n",
    "sum_predictions /= 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "061aa05c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T14:02:16.531808Z",
     "iopub.status.busy": "2024-08-04T14:02:16.531007Z",
     "iopub.status.idle": "2024-08-04T14:02:16.549066Z",
     "shell.execute_reply": "2024-08-04T14:02:16.548199Z"
    },
    "papermill": {
     "duration": 0.027978,
     "end_time": "2024-08-04T14:02:16.551065",
     "exception": false,
     "start_time": "2024-08-04T14:02:16.523087",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "example = pd.read_csv(TEST_SUBMISSION)\n",
    "example.target = test_predictions\n",
    "example.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 9094797,
     "sourceId": 63056,
     "sourceType": "competition"
    },
    {
     "datasetId": 5491495,
     "sourceId": 9099448,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 98935,
     "modelInstanceId": 74157,
     "sourceId": 88348,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 140.207438,
   "end_time": "2024-08-04T14:02:19.524404",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-08-04T13:59:59.316966",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
