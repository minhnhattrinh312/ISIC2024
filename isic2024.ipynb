{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2225a4ce",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-08-11T09:45:33.968200Z",
     "iopub.status.busy": "2024-08-11T09:45:33.967886Z",
     "iopub.status.idle": "2024-08-11T09:46:51.424786Z",
     "shell.execute_reply": "2024-08-11T09:46:51.423781Z"
    },
    "papermill": {
     "duration": 77.464232,
     "end_time": "2024-08-11T09:46:51.427243",
     "exception": false,
     "start_time": "2024-08-11T09:45:33.963011",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/isic2024-git/library/lightning-2.3.3-py3-none-any.whl\r\n",
      "Requirement already satisfied: PyYAML<8.0,>=5.4 in /opt/conda/lib/python3.10/site-packages (from lightning==2.3.3) (6.0.1)\r\n",
      "Requirement already satisfied: fsspec<2026.0,>=2022.5.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning==2.3.3) (2024.5.0)\r\n",
      "Requirement already satisfied: lightning-utilities<2.0,>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from lightning==2.3.3) (0.11.3.post0)\r\n",
      "Requirement already satisfied: numpy<3.0,>=1.17.2 in /opt/conda/lib/python3.10/site-packages (from lightning==2.3.3) (1.26.4)\r\n",
      "Requirement already satisfied: packaging<25.0,>=20.0 in /opt/conda/lib/python3.10/site-packages (from lightning==2.3.3) (21.3)\r\n",
      "Requirement already satisfied: torch<4.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from lightning==2.3.3) (2.1.2)\r\n",
      "Requirement already satisfied: torchmetrics<3.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from lightning==2.3.3) (1.4.0.post0)\r\n",
      "Requirement already satisfied: tqdm<6.0,>=4.57.0 in /opt/conda/lib/python3.10/site-packages (from lightning==2.3.3) (4.66.4)\r\n",
      "Requirement already satisfied: typing-extensions<6.0,>=4.4.0 in /opt/conda/lib/python3.10/site-packages (from lightning==2.3.3) (4.9.0)\r\n",
      "Requirement already satisfied: pytorch-lightning in /opt/conda/lib/python3.10/site-packages (from lightning==2.3.3) (2.3.3)\r\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning==2.3.3) (3.9.1)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from lightning-utilities<2.0,>=0.10.0->lightning==2.3.3) (69.0.3)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging<25.0,>=20.0->lightning==2.3.3) (3.1.1)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch<4.0,>=2.0.0->lightning==2.3.3) (3.13.1)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch<4.0,>=2.0.0->lightning==2.3.3) (1.13.0)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch<4.0,>=2.0.0->lightning==2.3.3) (3.2.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch<4.0,>=2.0.0->lightning==2.3.3) (3.1.2)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning==2.3.3) (23.2.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning==2.3.3) (6.0.4)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning==2.3.3) (1.9.3)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning==2.3.3) (1.4.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning==2.3.3) (1.3.1)\r\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning==2.3.3) (4.0.3)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch<4.0,>=2.0.0->lightning==2.3.3) (2.1.3)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch<4.0,>=2.0.0->lightning==2.3.3) (1.3.0)\r\n",
      "Requirement already satisfied: idna>=2.0 in /opt/conda/lib/python3.10/site-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning==2.3.3) (3.6)\r\n",
      "Installing collected packages: lightning\r\n",
      "Successfully installed lightning-2.3.3\r\n",
      "Processing /kaggle/input/isic2024-git/library/yacs-0.1.8-py3-none-any.whl\r\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from yacs==0.1.8) (6.0.1)\r\n",
      "Installing collected packages: yacs\r\n",
      "Successfully installed yacs-0.1.8\r\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "from IPython.display import clear_output\n",
    "!pip install \"/kaggle/input/isic2024-git/library/lightning-2.3.3-py3-none-any.whl\"\n",
    "!pip install \"/kaggle/input/isic2024-git/library/yacs-0.1.8-py3-none-any.whl\"\n",
    "# clear_output()\n",
    "import numpy as np  # linear algebra\n",
    "import pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import os\n",
    "import sys\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset\n",
    "import torch._dynamo\n",
    "\n",
    "torch._dynamo.config.suppress_errors = True\n",
    "\n",
    "import timm\n",
    "sys.path.append(\"/kaggle/input/isic2024-git\")\n",
    "import h5py\n",
    "import io\n",
    "from tqdm import tqdm\n",
    "from classification import *\n",
    "from lightning.pytorch import Trainer\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "torch.set_float32_matmul_precision(\"high\")\n",
    "class ISIC_test_image(Dataset):\n",
    "    def __init__(self, hdf5_path, metadata):\n",
    "        self.hdf5_path = hdf5_path\n",
    "        self.isic_ids = metadata[\"isic_id\"].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.isic_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_data = h5py.File(self.hdf5_path, mode=\"r\")[self.isic_ids[idx]][()]\n",
    "        image = Image.open(io.BytesIO(image_data)).resize((cfg.DATA.IMG_SIZE))\n",
    "        image = transforms.ToTensor()(image)\n",
    "\n",
    "        return image\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed0c8bab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T09:46:51.436816Z",
     "iopub.status.busy": "2024-08-11T09:46:51.436282Z",
     "iopub.status.idle": "2024-08-11T09:46:51.440879Z",
     "shell.execute_reply": "2024-08-11T09:46:51.440018Z"
    },
    "papermill": {
     "duration": 0.011323,
     "end_time": "2024-08-11T09:46:51.442846",
     "exception": false,
     "start_time": "2024-08-11T09:46:51.431523",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TEST_METADATA = \"/kaggle/input/isic-2024-challenge/test-metadata.csv\"\n",
    "TEST_HDF5 = \"/kaggle/input/isic-2024-challenge/test-image.hdf5\"\n",
    "TEST_SUBMISSION = \"/kaggle/input/isic-2024-challenge/sample_submission.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9fd6539",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T09:46:51.451089Z",
     "iopub.status.busy": "2024-08-11T09:46:51.450840Z",
     "iopub.status.idle": "2024-08-11T09:46:51.471033Z",
     "shell.execute_reply": "2024-08-11T09:46:51.470345Z"
    },
    "papermill": {
     "duration": 0.026448,
     "end_time": "2024-08-11T09:46:51.472934",
     "exception": false,
     "start_time": "2024-08-11T09:46:51.446486",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_metadata = pd.read_csv(TEST_METADATA)\n",
    "\n",
    "test_loader = ISIC_test_image(TEST_HDF5, test_metadata)\n",
    "\n",
    "test_dataset = DataLoader(\n",
    "    test_loader,\n",
    "    batch_size=16,\n",
    "    num_workers=4,\n",
    "    prefetch_factor=8,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9243f319",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T09:46:51.481644Z",
     "iopub.status.busy": "2024-08-11T09:46:51.480995Z",
     "iopub.status.idle": "2024-08-11T09:47:19.342757Z",
     "shell.execute_reply": "2024-08-11T09:47:19.341552Z"
    },
    "papermill": {
     "duration": 27.868383,
     "end_time": "2024-08-11T09:47:19.344936",
     "exception": false,
     "start_time": "2024-08-11T09:46:51.476553",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prediction Loop:   0%|          | 0/1 [00:00<?, ?it/s][2024-08-11 09:47:05,761] torch._dynamo.convert_frame: [WARNING] WON'T CONVERT forward /kaggle/input/isic2024-git/classification/convNext_model.py line 110 \n",
      "[2024-08-11 09:47:05,761] torch._dynamo.convert_frame: [WARNING] due to: \n",
      "[2024-08-11 09:47:05,761] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):\n",
      "[2024-08-11 09:47:05,761] torch._dynamo.convert_frame: [WARNING]   File \"/opt/conda/lib/python3.10/site-packages/torch/_inductor/scheduler.py\", line 1630, in create_backend\n",
      "[2024-08-11 09:47:05,761] torch._dynamo.convert_frame: [WARNING]     raise RuntimeError(\n",
      "[2024-08-11 09:47:05,761] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "[2024-08-11 09:47:05,761] torch._dynamo.convert_frame: [WARNING] RuntimeError: Found Tesla P100-PCIE-16GB which is too old to be supported by the triton GPU compiler, which is used as the backend. Triton only supports devices of CUDA Capability >= 7.0, but your device is of CUDA capability 6.0\n",
      "[2024-08-11 09:47:05,761] torch._dynamo.convert_frame: [WARNING] \n",
      "[2024-08-11 09:47:05,761] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "[2024-08-11 09:47:05,761] torch._dynamo.convert_frame: [WARNING] \n",
      "[2024-08-11 09:47:05,761] torch._dynamo.convert_frame: [WARNING] \n",
      "[2024-08-11 09:47:13,448] torch._dynamo.convert_frame: [WARNING] WON'T CONVERT forward_features /kaggle/input/isic2024-git/classification/convNext_model.py line 104 \n",
      "[2024-08-11 09:47:13,448] torch._dynamo.convert_frame: [WARNING] due to: \n",
      "[2024-08-11 09:47:13,448] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):\n",
      "[2024-08-11 09:47:13,448] torch._dynamo.convert_frame: [WARNING]   File \"/opt/conda/lib/python3.10/site-packages/torch/_inductor/scheduler.py\", line 1630, in create_backend\n",
      "[2024-08-11 09:47:13,448] torch._dynamo.convert_frame: [WARNING]     raise RuntimeError(\n",
      "[2024-08-11 09:47:13,448] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "[2024-08-11 09:47:13,448] torch._dynamo.convert_frame: [WARNING] RuntimeError: Found Tesla P100-PCIE-16GB which is too old to be supported by the triton GPU compiler, which is used as the backend. Triton only supports devices of CUDA Capability >= 7.0, but your device is of CUDA capability 6.0\n",
      "[2024-08-11 09:47:13,448] torch._dynamo.convert_frame: [WARNING] \n",
      "[2024-08-11 09:47:13,448] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "[2024-08-11 09:47:13,448] torch._dynamo.convert_frame: [WARNING] \n",
      "[2024-08-11 09:47:13,448] torch._dynamo.convert_frame: [WARNING] \n",
      "[2024-08-11 09:47:13,679] torch._dynamo.convert_frame: [WARNING] WON'T CONVERT forward /opt/conda/lib/python3.10/site-packages/torch/nn/modules/container.py line 213 \n",
      "[2024-08-11 09:47:13,679] torch._dynamo.convert_frame: [WARNING] due to: \n",
      "[2024-08-11 09:47:13,679] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):\n",
      "[2024-08-11 09:47:13,679] torch._dynamo.convert_frame: [WARNING]   File \"/opt/conda/lib/python3.10/site-packages/torch/_inductor/scheduler.py\", line 1630, in create_backend\n",
      "[2024-08-11 09:47:13,679] torch._dynamo.convert_frame: [WARNING]     raise RuntimeError(\n",
      "[2024-08-11 09:47:13,679] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "[2024-08-11 09:47:13,679] torch._dynamo.convert_frame: [WARNING] RuntimeError: Found Tesla P100-PCIE-16GB which is too old to be supported by the triton GPU compiler, which is used as the backend. Triton only supports devices of CUDA Capability >= 7.0, but your device is of CUDA capability 6.0\n",
      "[2024-08-11 09:47:13,679] torch._dynamo.convert_frame: [WARNING] \n",
      "[2024-08-11 09:47:13,679] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "[2024-08-11 09:47:13,679] torch._dynamo.convert_frame: [WARNING] \n",
      "[2024-08-11 09:47:13,679] torch._dynamo.convert_frame: [WARNING] \n",
      "[2024-08-11 09:47:14,228] torch._dynamo.convert_frame: [WARNING] WON'T CONVERT forward /kaggle/input/isic2024-git/classification/convNext_model.py line 133 \n",
      "[2024-08-11 09:47:14,228] torch._dynamo.convert_frame: [WARNING] due to: \n",
      "[2024-08-11 09:47:14,228] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):\n",
      "[2024-08-11 09:47:14,228] torch._dynamo.convert_frame: [WARNING]   File \"/opt/conda/lib/python3.10/site-packages/torch/_inductor/scheduler.py\", line 1630, in create_backend\n",
      "[2024-08-11 09:47:14,228] torch._dynamo.convert_frame: [WARNING]     raise RuntimeError(\n",
      "[2024-08-11 09:47:14,228] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "[2024-08-11 09:47:14,228] torch._dynamo.convert_frame: [WARNING] RuntimeError: Found Tesla P100-PCIE-16GB which is too old to be supported by the triton GPU compiler, which is used as the backend. Triton only supports devices of CUDA Capability >= 7.0, but your device is of CUDA capability 6.0\n",
      "[2024-08-11 09:47:14,228] torch._dynamo.convert_frame: [WARNING] \n",
      "[2024-08-11 09:47:14,228] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "[2024-08-11 09:47:14,228] torch._dynamo.convert_frame: [WARNING] \n",
      "[2024-08-11 09:47:14,228] torch._dynamo.convert_frame: [WARNING] \n",
      "[2024-08-11 09:47:14,672] torch._dynamo.convert_frame: [WARNING] WON'T CONVERT forward /kaggle/input/isic2024-git/classification/convNext_model.py line 33 \n",
      "[2024-08-11 09:47:14,672] torch._dynamo.convert_frame: [WARNING] due to: \n",
      "[2024-08-11 09:47:14,672] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):\n",
      "[2024-08-11 09:47:14,672] torch._dynamo.convert_frame: [WARNING]   File \"/opt/conda/lib/python3.10/site-packages/torch/_inductor/scheduler.py\", line 1630, in create_backend\n",
      "[2024-08-11 09:47:14,672] torch._dynamo.convert_frame: [WARNING]     raise RuntimeError(\n",
      "[2024-08-11 09:47:14,672] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "[2024-08-11 09:47:14,672] torch._dynamo.convert_frame: [WARNING] RuntimeError: Found Tesla P100-PCIE-16GB which is too old to be supported by the triton GPU compiler, which is used as the backend. Triton only supports devices of CUDA Capability >= 7.0, but your device is of CUDA capability 6.0\n",
      "[2024-08-11 09:47:14,672] torch._dynamo.convert_frame: [WARNING] \n",
      "[2024-08-11 09:47:14,672] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "[2024-08-11 09:47:14,672] torch._dynamo.convert_frame: [WARNING] \n",
      "[2024-08-11 09:47:14,672] torch._dynamo.convert_frame: [WARNING] \n",
      "Prediction Loop: 100%|██████████| 1/1 [00:26<00:00, 26.75s/it]\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = convnext_tiny(\n",
    "    pretrained=False,\n",
    "    in_22k=cfg.TRAIN.CONVEXT.IN22K,\n",
    "    in_chans=cfg.DATA.IN_CHANNEL,\n",
    "    num_classes=cfg.DATA.NUM_CLASS,\n",
    "    drop_path_rate=cfg.TRAIN.CONVEXT.DROPOUT,\n",
    ")\n",
    "\n",
    "checkpoint_dict = {\n",
    "    \"fold1\": \"/kaggle/input/convnext_tiny/pytorch/default/1/ckpt_auc_0.1934-v4.ckpt\",\n",
    "    \"fold2\": \"/kaggle/input/convnext_tiny/pytorch/default/1/ckpt_auc_0.1936-v2.ckpt\",\n",
    "    \"fold3\": \"/kaggle/input/convnext_tiny/pytorch/default/1/ckpt_recall_0.9617.ckpt\",\n",
    "    \"fold4\": \"/kaggle/input/convnext_tiny/pytorch/default/1/ckpt_recall_0.9671.ckpt\",\n",
    "    \"fold5\": \"/kaggle/input/convnext_tiny/pytorch/default/1/ckpt_recall_0.9719.ckpt\",\n",
    "}\n",
    "classifier = Classifier(\n",
    "    model,\n",
    "    cfg.DATA.CLASS_WEIGHT,\n",
    "    cfg.DATA.NUM_CLASS,\n",
    "    cfg.OPT.LEARNING_RATE,\n",
    "    cfg.OPT.FACTOR_LR,\n",
    "    cfg.OPT.PATIENCE_LR,\n",
    ")\n",
    "classifier = classifier.to(device)\n",
    "sum_predictions = 0\n",
    "test_predictions = []\n",
    "classifier.eval()\n",
    "with torch.inference_mode():\n",
    "    for images in tqdm(test_dataset, desc=\"Prediction Loop\"):\n",
    "        images = images.to(device)\n",
    "        preds = 0\n",
    "        for fold in range(1, 6):\n",
    "            classifier = Classifier.load_from_checkpoint(\n",
    "                checkpoint_path=checkpoint_dict[f\"fold{fold}\"],\n",
    "                model=model,\n",
    "                class_weight=cfg.DATA.CLASS_WEIGHT,\n",
    "                num_classes=cfg.DATA.NUM_CLASS,\n",
    "                learning_rate=cfg.OPT.LEARNING_RATE,\n",
    "                factor_lr=cfg.OPT.FACTOR_LR,\n",
    "                patience_lr=cfg.OPT.PATIENCE_LR,\n",
    "            )\n",
    "            preds += classifier(images)\n",
    "            \n",
    "        preds /= 5\n",
    "        test_predictions.append(preds.cpu().numpy()[:, 1])\n",
    "\n",
    "test_predictions = np.concatenate(test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57941118",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T09:47:19.356840Z",
     "iopub.status.busy": "2024-08-11T09:47:19.356019Z",
     "iopub.status.idle": "2024-08-11T09:47:19.370237Z",
     "shell.execute_reply": "2024-08-11T09:47:19.369537Z"
    },
    "papermill": {
     "duration": 0.022306,
     "end_time": "2024-08-11T09:47:19.372151",
     "exception": false,
     "start_time": "2024-08-11T09:47:19.349845",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "example = pd.read_csv(TEST_SUBMISSION)\n",
    "example.target = test_predictions\n",
    "example.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8151dddf",
   "metadata": {
    "papermill": {
     "duration": 0.004584,
     "end_time": "2024-08-11T09:47:19.381370",
     "exception": false,
     "start_time": "2024-08-11T09:47:19.376786",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 9094797,
     "sourceId": 63056,
     "sourceType": "competition"
    },
    {
     "datasetId": 5491495,
     "isSourceIdPinned": true,
     "sourceId": 9150760,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 102390,
     "modelInstanceId": 77772,
     "sourceId": 92768,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 111.260886,
   "end_time": "2024-08-11T09:47:22.356234",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-08-11T09:45:31.095348",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
