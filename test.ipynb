{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nhattm/.conda/envs/isic/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "import torch\n",
    "import numpy as np\n",
    "from torchmetrics.classification import BinaryAUROC\n",
    "from classification import *\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from libauc.losses import pAUCLoss\n",
    "from libauc.sampler import DualSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = 3\n",
    "df_data = pd.read_csv(\"/home/nhattm/ISIC2024/dataset/data_images.csv\")\n",
    "df_train = df_data[df_data[\"fold\"] != fold].reset_index(drop=True)\n",
    "df_test = df_data[df_data[\"fold\"] == fold].reset_index(drop=True)\n",
    "transforms = get_transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = ISIC_Loader(df_test)[11095]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image, label = test_dataset\n",
    "# image_aug = transforms(image)\n",
    "# plt.imshow(image_aug[0].permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    50000\n",
       "1     5499\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "fold =1\n",
    "df_data = pd.read_csv(\"./dataset/data_images.csv\")\n",
    "# get dataframe train and test\n",
    "df_train = df_data[df_data[\"fold\"] != fold].reset_index(drop=True)\n",
    "df_test = df_data[df_data[\"fold\"] == fold].reset_index(drop=True)\n",
    "train_loader = ISIC_Loader(df_train)\n",
    "test_loader = ISIC_Loader(df_test)\n",
    "# Define data loaders for the training and test data\n",
    "\n",
    "\n",
    "test_dataset = DataLoader(\n",
    "    test_loader,\n",
    "    batch_size=cfg.TRAIN.BATCH_SIZE,\n",
    "    num_workers=cfg.TRAIN.NUM_WORKERS,\n",
    "    prefetch_factor=cfg.TRAIN.PREFETCH_FACTOR,\n",
    "        )\n",
    "model = convnext_small(\n",
    "    pretrained=cfg.TRAIN.PRETRAIN,\n",
    "    in_22k=cfg.TRAIN.CONVEXT.IN22K,\n",
    "    in_chans=cfg.DATA.IN_CHANNEL,\n",
    "    num_classes=cfg.DATA.NUM_CLASS,\n",
    "    drop_path_rate=cfg.TRAIN.CONVEXT.DROPOUT,\n",
    ")\n",
    "classifier = Classifier(\n",
    "    model,\n",
    "    cfg.DATA.CLASS_WEIGHT,\n",
    "    cfg.DATA.NUM_CLASS,\n",
    "    cfg.OPT.LEARNING_RATE,\n",
    "    cfg.OPT.FACTOR_LR,\n",
    "    cfg.OPT.PATIENCE_LR,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = DualSampler(train_loader, batch_size=cfg.TRAIN.BATCH_SIZE, sampling_rate=0.1)\n",
    "train_dataset = DataLoader(\n",
    "    train_loader,\n",
    "    batch_size=cfg.TRAIN.BATCH_SIZE,\n",
    "    pin_memory=True,\n",
    "    shuffle=False,\n",
    "    num_workers=cfg.TRAIN.NUM_WORKERS,\n",
    "    drop_last=True,\n",
    "    prefetch_factor=cfg.TRAIN.PREFETCH_FACTOR,\n",
    "    sampler=sampler,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pd.read_csv(\"./dataset/data_images.csv\")\n",
    "# get dataframe train and test\n",
    "df_train = df_data[df_data[\"fold\"] != fold].reset_index(drop=True)\n",
    "df_test = df_data[df_data[\"fold\"] == fold].reset_index(drop=True)\n",
    "# duplicate df_Train to df_train_aug that all columns have target==1 will be duplicated 10 times\n",
    "df_train_aug = df_train[df_train[\"target\"] == 1].copy()\n",
    "df_train_aug = pd.concat([df_train_aug] * 8, ignore_index=True)\n",
    "df_train = pd.concat([df_train, df_train_aug], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4522 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4522/4522 [00:01<00:00, 4395.16it/s]\n",
      "100%|██████████| 584/584 [00:00<00:00, 8122.03it/s]\n",
      "/tmp/ipykernel_1367697/1124182564.py:58: DtypeWarning: Columns (51,52) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_train_2024 = pd.read_csv(\"./dataset/data2024/train-metadata.csv\")\n",
      "100%|██████████| 393/393 [00:00<00:00, 8652.95it/s]\n",
      "100%|██████████| 55000/55000 [01:23<00:00, 656.13it/s]\n",
      "100%|██████████| 55000/55000 [01:23<00:00, 658.24it/s]\n",
      "100%|██████████| 55000/55000 [01:23<00:00, 659.63it/s]\n",
      "100%|██████████| 55000/55000 [01:23<00:00, 658.99it/s]\n",
      "100%|██████████| 55000/55000 [01:23<00:00, 656.90it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# add path to this file\n",
    "import sys\n",
    "\n",
    "# sys.path.append(os.path.dirname(os.path.abspath(__file__)))\n",
    "\n",
    "# create a df for 3 datasets but get the positive samples from 2019 and 2020 only\n",
    "# load the data\n",
    "df_train_2019a = pd.read_csv(\"./dataset/data2019/ISIC_2019_Training_Metadata.csv\")\n",
    "df_train_2019b = pd.read_csv(\"./dataset/data2019/train-groundtruth.csv\")\n",
    "# concatenate the two dataframes, cat 2019a with 2019b\n",
    "df_train_2019 = pd.concat([df_train_2019a, df_train_2019b], axis=1)\n",
    "# remove columns :lesion_id,Unnamed: 0\n",
    "df_train_2019 = df_train_2019.drop(columns=[\"Unnamed: 0\", \"isic_id\", \"lesion_id\"], axis=1)\n",
    "df_train_2019 = df_train_2019.rename(columns={\"image\": \"isic_id\"})\n",
    "\n",
    "# get the positive samples from 2019\n",
    "df_train_2019_positives = df_train_2019[df_train_2019[\"target\"] == 1].copy()\n",
    "# loop through the dataframe and add the address of the image to the dataframe\n",
    "for isic_id in tqdm(df_train_2019_positives[\"isic_id\"]):\n",
    "    image_path1 = f\"./dataset/data2019/image/{isic_id}.jpg\"\n",
    "    image_path2 = f\"./dataset/data2019/image/{isic_id}_downsampled.jpg\"\n",
    "\n",
    "    if os.path.exists(image_path1):\n",
    "        df_train_2019_positives.loc[df_train_2019_positives[\"isic_id\"] == isic_id, \"image_path\"] = image_path1\n",
    "    elif os.path.exists(image_path2):\n",
    "        df_train_2019_positives.loc[df_train_2019_positives[\"isic_id\"] == isic_id, \"image_path\"] = image_path2\n",
    "    else:\n",
    "        print(f\"Image {isic_id} not found\")\n",
    "        break\n",
    "\n",
    "df_train_2020 = pd.read_csv(\"./dataset/data2020/train.csv\")\n",
    "# drop the diagnosis, benign_malignant columns\n",
    "df_train_2020 = df_train_2020.drop(columns=[\"diagnosis\", \"benign_malignant\"], axis=1)\n",
    "# change name of the columns 2020 to the same 2019:\n",
    "# image_name -> image, anatom_site_general_challenge -> anatom_site_general\n",
    "df_train_2020 = df_train_2020.rename(\n",
    "    columns={\"image_name\": \"isic_id\", \"anatom_site_general_challenge\": \"anatom_site_general\"}\n",
    ")\n",
    "\n",
    "# get the positive samples from 2020\n",
    "df_train_2020_positives = df_train_2020[df_train_2020[\"target\"] == 1].copy()\n",
    "\n",
    "for isic_id in tqdm(df_train_2020_positives[\"isic_id\"]):\n",
    "    image_path = f\"./dataset/data2020/image/{isic_id}.jpg\"\n",
    "\n",
    "    if os.path.exists(image_path):\n",
    "        df_train_2020_positives.loc[df_train_2020_positives[\"isic_id\"] == isic_id, \"image_path\"] = image_path\n",
    "    else:\n",
    "        print(f\"Image {isic_id} not found\")\n",
    "        break\n",
    "\n",
    "# load data 2024\n",
    "df_train_2024 = pd.read_csv(\"./dataset/data2024/train-metadata.csv\")\n",
    "df_test_2024 = pd.read_csv(\"./dataset/data2024/test-metadata.csv\")\n",
    "# remove columns in df 2024 train if it not in df 2024 test\n",
    "remove_columns = [col for col in df_train_2024.columns if col not in df_test_2024.columns]\n",
    "remove_columns.remove(\"target\")\n",
    "df_train_2024 = df_train_2024.drop(columns=remove_columns, axis=1)\n",
    "# get all images with target == 1 and 50000 images with target == 0\n",
    "# to balance the dataset\n",
    "df_train_2024 = df_train_2024.sort_values(by=\"target\", ascending=False)\n",
    "\n",
    "df_train_2024_positives = df_train_2024[df_train_2024[\"target\"] == 1].copy()\n",
    "for isic_id in tqdm(df_train_2024_positives[\"isic_id\"]):\n",
    "    image_path = f\"./dataset/data2024/image/{isic_id}.jpg\"\n",
    "\n",
    "    if os.path.exists(image_path):\n",
    "        df_train_2024_positives.loc[df_train_2024_positives[\"isic_id\"] == isic_id, \"image_path\"] = image_path\n",
    "    else:\n",
    "        print(f\"Image {isic_id} not found\")\n",
    "        break\n",
    "\n",
    "df_train_positives = pd.concat([df_train_2019_positives, df_train_2020_positives, df_train_2024_positives], axis=0)\n",
    "df_train_positives = df_train_positives.reset_index(drop=True)\n",
    "# spilt df_train_positives into 5 folds, each fold has the same number of positive samples\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "df_train_positives = df_train_positives[[\"isic_id\", \"target\", \"image_path\"]]\n",
    "df_train_positives[\"fold\"] = -1\n",
    "for fold, (train_index, val_index) in enumerate(skf.split(df_train_positives, df_train_positives[\"target\"])):\n",
    "    df_train_positives.loc[val_index, \"fold\"] = fold + 1\n",
    "\n",
    "# get the negative samples from 2024\n",
    "df_train_2024 = df_train_2024[[\"isic_id\", \"target\"]]\n",
    "df_train_2024_negatives = df_train_2024[df_train_2024[\"target\"] == 0].copy()\n",
    "# for training each fold, we use 44000 negative samples for train and 5500 negative samples for validation from df_train_2024_negatives\n",
    "for fold in range(1, 6):\n",
    "    df_negatives = df_train_2024_negatives[55000 * (fold - 1) : 55000 * fold].copy().reset_index(drop=True)\n",
    "    # get 11000 negative samples for validation so change the \"fold\" column to -1\n",
    "    df_negatives.loc[44000:, \"fold\"] = fold\n",
    "    df_negatives.loc[:44000, \"fold\"] = -1\n",
    "    for isic_id in tqdm(df_negatives[\"isic_id\"]):\n",
    "        image_path = f\"./dataset/data2024/image/{isic_id}.jpg\"\n",
    "\n",
    "        if os.path.exists(image_path):\n",
    "            df_negatives.loc[df_negatives[\"isic_id\"] == isic_id, \"image_path\"] = image_path\n",
    "        else:\n",
    "            print(f\"Image {isic_id} not found\")\n",
    "            break\n",
    "    # concatenate the negative samples with the positive samples\n",
    "    df_train_fold = pd.concat([df_negatives, df_train_positives], axis=0).reset_index(drop=True)\n",
    "    # save the dataframe to csv file\n",
    "    df_train_fold.to_csv(f\"./dataset/data_images_fold{fold}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_fold = pd.read_csv(\"./dataset/data_images_fold2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    55000\n",
       "1     5499\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_fold.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_train_positives' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf_train_positives\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_train_positives' is not defined"
     ]
    }
   ],
   "source": [
    "df_train_positives[\"target\"].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tomodl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
